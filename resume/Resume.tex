% resume.tex
% (C)2014 Abhiram Ravi (abhiram.ravi.s@gmail.com)
% http://www.cse.iitm.ac.in/~abhiram/
% Modified version of Slinky's Resume template - http://arun.chagantys.org
%

% You can add the option 'web'
\documentclass[letterpaper,10pt]{resume}
\usepackage{fullpage}
\usepackage{multicol}
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\hypersetup{
    colorlinks=true,
    linkcolor=MidnightBlue,
    filecolor=magenta,      
    urlcolor=MidnightBlue,
    pdfnewwindow=true,
}
 
\urlstyle{same}
\usepackage[letterspace=15]{microtype}
\setlength{\columnseprule}{0pt} 

\author{\textcolor{grey}{Aishwarya Padmakumar}}
\websitename{\textcolor{grey}{http://www.cs.utexas.edu/$\sim$aish/}}
\website{http://www.cs.utexas.edu/~aish/}
\email{aish@cs.utexas.edu}
\address{3.424B, 2317 Speedway, Austin, TX 78712}

\renewcommand{\labelitemii}{$\circ$}

\begin{document}
\lsstyle
{
\resumeheader

\section{RESEARCH INTERESTS}
Grounded Language Learning, Human-robot-Dialog, Dialog Systems, Natural Language Processing, Machine Learning
\vspace{0.2cm}

\section{EDUCATION}

\begin{minipage}[t]{0.8\textwidth}
	{\sf \textbf{PhD, University of Texas at Austin}} \\
	Computer Science \\
	{\small \sf \textbf{Advisor}: Raymond J. Mooney} \\
	{\small \sf \textbf{Research}: Improving grounded language learning for robotics} \\	
	
\end{minipage}\begin{minipage}[t]{0.2\textwidth} 
	\begin{flushright}
		{\small \sf Austin, TX, USA} \\
		{\sf Aug. 2015 -- Present}
	\end{flushright}		
\end{minipage}
\vspace{0.3cm}

\begin{minipage}[t]{0.8\textwidth}
	{\sf \textbf{B.Tech.(Hons.), Indian Institute of Technology, Madras}} \\
	{\small \sf\textbf{Major}}: Computer Science and Engineering; {\small \sf\textbf{Minor}}: Operations Research \\
	{\small \sf \textbf{Advisor}: Balaraman Ravindran} \\
	{\small \sf \textbf{Thesis}: Improving aggregate diversity in recommendation systems} \\	
	
\end{minipage}\begin{minipage}[t]{0.2\textwidth} 
	\begin{flushright}
		{\small \sf Chennai, India} \\
		{\sf Aug. 2011 -- May 2015}
	\end{flushright}		
\end{minipage}
\vspace{0.1cm}


\section{PUBLICATIONS AND PATENTS}
\begin{itemize}
\item  ``Jointly Improving Parsing and Perception for Natural Language Commands through Human-Robot Dialog'' \\
\textit{Jesse Thomason, \textbf{Aishwarya Padmakumar}, Jivko Sinapov, Nick Walker, Yuqian Jiang, Harel Yedidsion, Justin Hart, Peter Stone, and Raymond J. Mooney.} \\
In The Journal of Artificial Intelligence Research (JAIR), Vol. 67 (2020), pp. 327-374.
\vspace{0.2cm}

\item  ``Improving Grounded Natural Language Understanding through Human-Robot Dialog'' \\
\textit{Jesse Thomason, \textbf{Aishwarya Padmakumar}, Jivko Sinapov, Nick Walker, Yuqian Jiang, Harel Yedidsion, Justin Hart, Peter Stone, and Raymond J. Mooney.} \\
In Proceedings of the International Conference on Robotics and Automation (ICRA), 2019. \\
Also presented at the SIGDIAL Special Session on Physically Situated Dialogue (RoboDIAL), 2018. \\
Also presented at the RSS Workshop on Models and Representations for Natural Human-Robot Communication (MRHRC), 2018. 
\vspace{0.2cm}

\item  ``Learning a Policy for Opportunistic Active Learning'' \\
\textit{\textbf{Aishwarya Padmakumar}, Peter Stone, and Raymond J. Mooney. } \\
In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-18), Brussels, Belgium, November 2018. 
\vspace{0.2cm}

\item  ``Interaction and Autonomy in RoboCup@Home and Building-Wide Intelligence'' \\
\textit{Justin Hart, Harel Yedidsion, Yuqian Jiang, Nick Walker, Rishi Shah, Jesse Thomason, \textbf{Aishwarya Padmakumar}, Rolando Fernandez, Jivko Sinapov, Raymond Mooney and Peter Stone. } \\
In Artificial Intelligence (AI) for Human-Robot Interaction (HRI) symposium, AAAI Fall Symposium Series, Arlington, Virginia, October 2018. 
\vspace{0.2cm}

\item  ``Opportunistic Active Learning for Grounding Natural Language Descriptions'' \\
\textit{Jesse Thomason, \textbf{Aishwarya Padmakumar}, Jivko Sinapov, Justin Hart, Peter Stone, and Raymond J. Mooney.} \\
In Proceedings of the 1st Annual Conference on Robot Learning (CoRL-17), Mountain View, California, November 2017. 
\vspace{0.2cm}

\item  ``Integrated Learning of Dialog Strategies and Semantic Parsing'' \\
\textit{\textbf{Aishwarya Padmakumar}, Jesse Thomason and Raymond J. Mooney} \\
In proceedings of the 15th European chapter of the Association for Computational Linguistics (EACL '17) 
\vspace{0.2cm}


\item  ``Automated Linguistic Personalization of Targeted Marketing Messages Mining User-Generated Text on Social Media'' \\
\textit{Rishiraj Saha Roy, \textbf{Aishwarya Padmakumar}, Guna Prasad Jeganathan and Ponnurangam Kumaraguru} \\
In proceedings of the 16th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing â€™15) \textit{(Best Paper Award)}
\vspace{0.2cm}

\item ``Linguistic Personalization of Messages for Targeted Campaigns'' \\
\textit{Rishiraj Saha Roy, Guna Prasaad Jeganathan, \textbf{Aishwarya Padmakumar} and Ponnurangam Kumaraguru}
USPTO Application No. 14/566,181, filed on 10 December 2014 \textit{(Patent pending)}
\vspace{0.2cm}
\end{itemize}

\section{OTHER ACADEMIC PROJECTS}
\begin{itemize}
  \credentialtwo
    {{Grounding Referring Expressions Using Multimodal Transformers}}
    {\sf Jan 2019 - Mar 2019}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Ray Mooney}}
    {}
    { 
    \small 
    Explored the use of a multimodal transformer consisting of alternating self and cross attention layers for grounding referring expressions in images. The system depended on extracting candidate bounding boxes or segments, and was found to underperform state-of-the-art models primarily due to limitations in the candidate generation phase. 
    }
   \vspace{0.2cm}


  \credentialtwo
    {{Grounding Referring Expressions Using Joint Embeddings}}
    {\sf October 2018 -- December 2018}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Ray Mooney}}
    {}
    { 
    \small 
	Learning to project image and word embeddings to a joint space in which images are close to words they apply to and vice versa. The model was found to be comparable to using independent 1 vs all classifiers for grounding referring expressions in images. 
    }
   \vspace{0.2cm}


  \credentialtwo
    {{Varying Ability to Observe in a Partially Observable World}}
    {\sf October 2016 -- December 2016}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Peter Stone}}
    {}
    { 
    \small 
	An attempt to extend belief monitoring in Bayes-Adaptive POMDPs to allow for an observation function that varies with time. Some proposed heuristic solutions based on recency weighting were found to work for cases where the changes in the observation function are not continuous. \footnote{The report can be found at \url{http://www.cs.utexas.edu/~aish/ut/RLProject.pdf}}
    }
   \vspace{0.2cm}   

  \credentialtwo
    {{Longer RNNs}}
    {\sf October 2016 -- November 2016}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Philipp Kr\"ahenb\"uhl}}
    {}
    { 
    \small 
	We attempted to improve the performance of RNNs on modeling long term dependencies by two methods - allowing for different weight matrices across time steps, and introducing residual connections. \footnote{The report can be found at \url{http://www.cs.utexas.edu/~aish/ut/DLProject2.pdf}}  
    }
   \vspace{0.2cm}   
 
  \credentialtwo
    {{Face to Age}}
    {\sf September 2016 -- October 2016}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Philipp Kr\"ahenb\"uhl}}
    {}
    { 
    \small 
	We fine-tuned VGGNet to predict the year in which given yearbook photographs were  taken. We compared the performance of different loss functions and visualized pixels relevant for classification.\footnote{The report can be found at \url{http://www.cs.utexas.edu/~aish/ut/DLProject1.pdf}} 
    }
   \vspace{0.2cm}  
 
  \credentialtwo
    {{Unsupervised Text Summarization Using Sentence Embeddings}}
    {\sf February 2016 -- May 2016}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Ray Mooney}}
    {}
    { 
    \small 
	We performed text summarization using clustering of sentence embeddings, learned to embed paraphrases near each other. We compared extractive and abstractive variants, as well as different embedding algorithms. \footnote{The report can be found at \url{http://www.cs.utexas.edu/~aish/ut/NLPProject.pdf}}
    }
   \vspace{0.2cm}
   
  \credentialtwo
    {{Visual Question Answering using Additional Localization Cues}}
    {\sf February 2016 -- May 2016}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Kristen Grauman}}
    {}
    { 
    \small 
	We attempted to improve a baseline VQA model by providing additional cues in the form of a bounding box obtained by natural language object retrieval on the image with the question as query, and a bounding box corresponding to a region which humans find interesting (high saliency). \footnote{The report can be found at \url{http://www.cs.utexas.edu/~aish/ut/VRProject.pdf}}
    }
   \vspace{0.2cm}
 
  \credentialtwo
    {{Modeling  Cooking  Tutorials  using  Hidden  Markov  Models}}
    {\sf August 2015 -- December 2015}
    {\it The University of Texas at Austin}{\textsf{Mentor: Prof. Scott Niekum}}
    {}
    { 
    \small This project aimed at recovering latent structure present in different web tutorials for the same task. We attempted to model cooking tutorials using HMMs and explored the use of different language models for observation probabilities. \footnote{The report can be found at \url{http://www.cs.utexas.edu/~aish/ut/RLFDProject.pdf}}
    }
   \vspace{0.2cm}
   
    \credentialtwo
    {{Improving Aggregate Diversity in Recommender Systems}}
    {\sf July 2014 -- May 2015}
    {\it Indian Institute of Technology, Madras}{\textsf{Mentor: Prof. Balaraman Ravindran}}
    {}
    { 
    \small This project was aimed at designing a new metric to evaluate aggregate diversity of recommendation systems, which is a measure of how often different items in the inventory get recommended. Different formulations were used to then optimize this metric. \footnote{The thesis can be found at \url{http://www.cs.utexas.edu/~aish/iitm/BTPThesis.pdf}}
    }
   \vspace{0.2cm}

\end{itemize}

\section{PROFESSIONAL EXPERIENCE}

\begin{itemize}
   \credential
      {Google} {May -- Aug 2018}
      {\textit{Mountain View, California}} {}
      {
		\small \begin{itemize}
			\item{Research intern in the Deep Dialogue team at Google Research.}
			\item{Worked on designing end-to-end models to enable a robot to navigate follow natural language route instructions in simulated home environments.}
		\end{itemize}		      
      }
  \vspace{0.2cm}
  
   \credential
      {Facebook} {June -- Aug 2017}
      {\textit{Menlo Park, California}} {}
      {
		\small \begin{itemize}
			\item{Research intern in Facebook Applied Machine Learning.}
			\item{Evaluated different models for supervised training of a task-oriented dialog system}
		\end{itemize}		      
      }
  \vspace{0.2cm}


   \credential
      {Adobe Reseach} {May -- July 2014}
      {\textit{Bangalore, India}} {}
      {
		\small \begin{itemize}
			\item{Research intern with the goal of exploiting word usage patterns mined from Twitter data to personalize text of ad messages for different user segments.}
			\item{Results patented and published at CICLing 2015, where we received the best paper award.}
		\end{itemize}		      
      }
  \vspace{0.2cm}

   \credential
      {Google} {May -- July 2013}
      {\textit{Bangalore, India}} {}
      {
		\small \begin{itemize}
			\item{Obtained through Google BOLD Programme for sophomore students.}
			\item{Added a feature to the Google Trader application to enable users to save their searches.}
			\item{Involved the use of map-reduce pipelines, remote procedure calls and dependency injections.}
		\end{itemize}		      
      }
  \vspace{0.2cm}
      
  \credential
      {SAP Labs India} {June -- July 2012}
      {\textit{Bangalore, India}} {}
      {
		\small \begin{itemize}
			\item{Web operations work - revamping the website for Charitra, a partner NGO of SAP.}
			\item{Back-end: Java, Storage: HANA-DB - A corporate In-memory database, Front-end: HTML, CSS, Javascript}
		\end{itemize}		      
      }
         \vspace{0.2cm}
\end{itemize}

\section{PROFESSIONAL SERVICE}
\begin{itemize}
\item \textbf{Conference Reviewing}
\begin{itemize}
\item Association for Computational Linguistics (ACL) 2019, 2020
\item Conference on Empirical Methods in Natural Language Processing (EMNLP) 2019
\item AAAI Conference on Artificial Intelligence (AAAI) 2019
\item Conference on Robot Learning (CoRL) 2019
\item Conference on Computational Natural Language Learning (CoNLL) 2019
\end{itemize}
\item \textbf{Workshop Reviewing}
\begin{itemize}
\item NAACL Student Research Workshop (SRW) 2019
\item NAACL Grounded Communication for Robotics (RoboNLP) 2019
\end{itemize}
\end{itemize}
\vspace{0.2cm}

\section{DEPARTMENT SERVICE}
\begin{itemize}
\item Organizer: UT Connecting Language Acquisition with Machine Perception Reading Group (Fall 2018 - Fall 2019)
\end{itemize}
\vspace{0.2cm}

\section{AWARDS}
\begin{itemize}
\item \textbf{Swati / Jayalakshmi Memorial Award (2015)}: Female student with best academic record at the end of pre-final semester in the B.Tech programme, IIT Madras.
\item \textbf{Kishore Vaigyanik Protsahan Yojana (2011)}: Fellowship awarded by the Department of Science and Technology, Govt. of India to promote interest in the basic sciences.
\end{itemize}
\vspace{0.2cm}

\section{COURSEWORK}
\begin{itemize}
\item \textbf{Graduate} : Deep Learning Seminar, Reinforcement Learning, Natural Language Processing, Visual Recognition, Robot Learning From Demonstration, Distributed Computing
\item \textbf{Undergraduate (advanced)} : Reinforcement Learning, Searching and Indexing in High Dimensional Datasets, Natural Language Processing, Data Mining, Social Network Analysis, Introduction to Machine Learning, Concurrent Programming, Distributed Algorithms 
\end{itemize}
\vspace{0.2cm}

\section{SKILLS}
\begin{itemize}
\item \textbf{Languages} : Python, C++, Matlab, PHP, Java
\item \textbf{Toolkits/Software/Frameworks} : Tensorflow, Caffe, ROS
\end{itemize}

\end{document}

